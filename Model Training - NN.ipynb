{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0615 16:41:26.569255 139705520310080 deprecation_wrapper.py:118] From /home/zander/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:97: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0615 16:41:26.569831 139705520310080 deprecation_wrapper.py:118] From /home/zander/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:97: The name tf.AttrValue is deprecated. Please use tf.compat.v1.AttrValue instead.\n",
      "\n",
      "W0615 16:41:26.570591 139705520310080 deprecation_wrapper.py:118] From /home/zander/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:97: The name tf.COMPILER_VERSION is deprecated. Please use tf.version.COMPILER_VERSION instead.\n",
      "\n",
      "W0615 16:41:26.570943 139705520310080 deprecation_wrapper.py:118] From /home/zander/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:97: The name tf.CXX11_ABI_FLAG is deprecated. Please use tf.sysconfig.CXX11_ABI_FLAG instead.\n",
      "\n",
      "W0615 16:41:26.571360 139705520310080 deprecation_wrapper.py:118] From /home/zander/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:97: The name tf.ConditionalAccumulator is deprecated. Please use tf.compat.v1.ConditionalAccumulator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "# Helper: Early stopping.\n",
    "early_stopper = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data saved from data cleaning\n",
    "X_train = pd.read_csv('training_features.csv', sep='\\t')\n",
    "Y_train = pd.read_csv('training_target.csv', sep='\\t')\n",
    "#Observe that is a class imbalance 80-20, should be fine. \n",
    "#Y_train['y'].value_counts(normalize=True)\n",
    "#Step 3 - Generate predictions:\n",
    "#Create predictions on the data in test.csv using each of your trained models.  \n",
    "#The predictions should be the class probabilities for belonging to the positive class (labeled '1').  \n",
    "#Because of the above, I one hot encoded the targets and used softmax in the model\n",
    "Y_train = pd.get_dummies(Y_train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_compile(network, input_shape, num_classes):\n",
    "    \"\"\"args is a dictionary\"\"\"\n",
    "    nb_layers = network['nb_layers']\n",
    "    nb_neurons = network['nb_neurons']\n",
    "    activation = network['activation']\n",
    "    optimizer = network['optimizer']\n",
    "    #Define the type of model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nb_neurons, activation=activation, input_shape=input_shape, name='input_layer'))\n",
    "    model.add(Dropout(0.2, name='dropout_input'))\n",
    "    for i in range(nb_layers):\n",
    "        model.add(Dense(nb_neurons, activation=activation, name='layer_{}'.format(i+1)))\n",
    "        #Dropout to help avoid over-fitting\n",
    "        model.add(Dropout(0.2, name='dropout_{}'.format(i+1)))\n",
    "    # Output layer.\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def evaluate_model(network, X_train,Y_train):\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    model = create_and_compile(network, input_shape,2)\n",
    "    early_stopper = EarlyStopping(patience=10)\n",
    "    model.fit(X_train, Y_train, verbose=0, epochs=100, validation_split=.25,callbacks=[early_stopper])\n",
    "    acc = model.evaluate(X_train,Y_train)[1]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_param_choices = {\n",
    "        'nb_layers': [1, 2, 3, 4],\n",
    "        'nb_neurons': [64, 128, 256, 512, 768, 1024],\n",
    "        'activation': ['relu', 'elu', 'tanh', 'sigmoid'],\n",
    "        'optimizer': ['rmsprop', 'adam', 'sgd', 'adagrad',\n",
    "                      'adadelta', 'adamax', 'nadam']\n",
    "    }\n",
    "import itertools\n",
    "keys, values = zip(*nn_param_choices.items())\n",
    "experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for x in range(25):\n",
    "    network = random.choice(experiments)\n",
    "    print('Evaluating model number {}'.format(x+1))\n",
    "    new_list.append(evaluate_model(network, X_train,Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a helpful way to change out the values without messing with the overall flow\n",
    "#I only tried a few combinations of neurons, layers and functions before I got to above 95% accuracy\n",
    "network = {'nb_layers': 4, 'nb_neurons': 128, 'activation': 'elu', 'optimizer': 'rmsprop'}\n",
    "nb_layers = network['nb_layers']\n",
    "nb_neurons = network['nb_neurons']\n",
    "activation = network['activation']\n",
    "optimizer = network['optimizer']\n",
    "input_shape = (X_train.shape[1],)\n",
    "#Define the type of model\n",
    "model = Sequential()\n",
    "model.add(Dense(nb_neurons, activation=activation, input_shape=input_shape, name='input_layer'))\n",
    "model.add(Dropout(0.2, name='dropout_input'))\n",
    "for i in range(nb_layers):\n",
    "    model.add(Dense(nb_neurons, activation=activation, name='layer_{}'.format(i+1)))\n",
    "    #Dropout to help avoid over-fitting\n",
    "    model.add(Dropout(0.2, name='dropout_{}'.format(i+1)))\n",
    "# Output layer.\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/250\n",
      " - 3s - loss: 0.1471 - acc: 0.9815 - val_loss: 0.1280 - val_acc: 0.9681\n",
      "Epoch 2/250\n",
      " - 6s - loss: 0.1394 - acc: 0.9821 - val_loss: 0.1327 - val_acc: 0.9815\n",
      "Epoch 3/250\n",
      " - 12s - loss: 0.1256 - acc: 0.9838 - val_loss: 0.1029 - val_acc: 0.9866\n",
      "Epoch 4/250\n",
      " - 12s - loss: 0.1245 - acc: 0.9840 - val_loss: 0.0813 - val_acc: 0.9857\n",
      "Epoch 5/250\n",
      " - 12s - loss: 0.1211 - acc: 0.9825 - val_loss: 0.1067 - val_acc: 0.9839\n",
      "Epoch 6/250\n",
      " - 12s - loss: 0.1134 - acc: 0.9850 - val_loss: 0.1202 - val_acc: 0.9889\n",
      "Epoch 7/250\n",
      " - 12s - loss: 0.1230 - acc: 0.9838 - val_loss: 0.1069 - val_acc: 0.9848\n",
      "Epoch 8/250\n",
      " - 12s - loss: 0.1170 - acc: 0.9840 - val_loss: 0.1036 - val_acc: 0.9882\n",
      "Epoch 9/250\n",
      " - 12s - loss: 0.1221 - acc: 0.9849 - val_loss: 0.1126 - val_acc: 0.9880\n",
      "Epoch 10/250\n",
      " - 12s - loss: 0.1189 - acc: 0.9855 - val_loss: 0.1146 - val_acc: 0.9861\n",
      "Epoch 11/250\n",
      " - 12s - loss: 0.1132 - acc: 0.9845 - val_loss: 0.1090 - val_acc: 0.9885\n",
      "Epoch 12/250\n",
      " - 12s - loss: 0.1219 - acc: 0.9846 - val_loss: 0.1096 - val_acc: 0.9847\n",
      "Epoch 13/250\n",
      " - 12s - loss: 0.1247 - acc: 0.9857 - val_loss: 0.1214 - val_acc: 0.9877\n",
      "Epoch 14/250\n",
      " - 12s - loss: 0.1500 - acc: 0.9843 - val_loss: 0.1321 - val_acc: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c06a4c860>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, verbose=2, epochs=250, validation_split=.25,callbacks=[early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 7s 185us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.992125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,Y_train)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save modeal for serving and re-loading\n",
    "model.save('model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check accuracy\n",
    "preds = model.predict(X_train)\n",
    "X_test = pd.read_csv('testing_targets.csv', sep='\\t')\n",
    "preds = model.predict(X_test)\n",
    "pd.DataFrame(preds).to_csv('results2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
