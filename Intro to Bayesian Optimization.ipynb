{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Bayesian Optimization.\n",
    "### Bayesian optimization is a sequential design strategy for global optimization of black-box functions that doesn't require derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "MAX_EVALS = 500\n",
    "N_FOLDS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to take parameters and return a compiled NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping after 10 epochs of little decrease in our loss function.\n",
    "early_stopper = EarlyStopping(patience=10)\n",
    "def create_and_compile(network):\n",
    "    \"\"\"Network is a dictionary\"\"\"\n",
    "    input_shape = (784,)\n",
    "    nb_layers = network['nb_layers']\n",
    "    nb_neurons = network['nb_neurons']\n",
    "    activation = network['activation']\n",
    "    optimizer = network['optimizer']\n",
    "    #learning_rate = network['learning_rate'] TODO figure out how to add learning rate to an activation function\n",
    "    #Define the type of model\n",
    "    #A Sequential model, is a series of fully connected (DENSE) layers that are connected in sequence.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nb_neurons, activation=activation, input_shape=input_shape, name='input_layer'))\n",
    "    model.add(Dropout(rate=0.2, name='dropout_input'))\n",
    "    for i in range(nb_layers):\n",
    "        model.add(Dense(nb_neurons, activation=activation, name='layer_{}'.format(i+1)))\n",
    "        #Dropout to help avoid over-fitting\n",
    "        model.add(Dropout(rate=0.2, name='dropout_{}'.format(i+1)))\n",
    "    # Output layer.\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our Cross validation function\n",
    "This is the function that we want to use to optimize towards. Typically you \"one hot encode\" your target to be a vector of records, N_classes. But since the Kfolds cross validation needs to take a single volumn vector, we will one hot encode the values AFTER we split our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model,X=None,y=None,num_fold=5):\n",
    "    kFold = StratifiedKFold(n_splits=5)\n",
    "    generator = kFold.split(X, y)\n",
    "    Y_train = np_utils.to_categorical(y, 10)\n",
    "    scores = []\n",
    "    for val in generator:\n",
    "        model.fit(x=X[val[0]], y=Y_train[val[0]], batch_size=512,\n",
    "                  validation_data = [X[val[1]],Y_train[val[1]]],\n",
    "                  epochs=100, verbose=0, callbacks = [early_stopper])\n",
    "        scores.append(model.evaluate(X[val[1]],Y_train[val[1]]))\n",
    "    return np.array(scores)[:,1].mean() # 1 is accuracy, 0 is loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the y label to see the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(y_train[:], edgecolor = 'k'); \n",
    "plt.xlabel('Label'); plt.ylabel('Count'); plt.title('Counts of Labels');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n",
      "Train matrix shape (60000, 784)\n",
      "Test matrix shape (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# let's print the shape before we reshape and normalize\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n",
    "\n",
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# print the final input shape ready for training\n",
    "print(\"Train matrix shape\", X_train.shape)\n",
    "print(\"Test matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12005/12005 [==============================] - 1s 102us/step\n",
      "12002/12002 [==============================] - 1s 95us/step\n",
      "12000/12000 [==============================] - 1s 96us/step\n",
      "11997/11997 [==============================] - 1s 94us/step\n",
      "11996/11996 [==============================] - 1s 94us/step\n",
      "The baseline score on the test set is 0.9935.\n",
      "The baseline training time is 70.1870 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "network = {'nb_layers':1, 'nb_neurons':784, 'activation':'relu','optimizer':'adam'}\n",
    "model = create_and_compile(network)\n",
    "results = cross_validate(model, X_train, y_train)\n",
    "train_time = timer() - start\n",
    "\n",
    "print('The baseline score on the test set is {:.4f}.'.format(results))\n",
    "print('The baseline training time is {:.4f} seconds'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "def objective(params, n_folds = 5):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    sys.stdout.flush()\n",
    "    start = timer()\n",
    "    #When using Hyperpot to generate our lists, it creates them as floats, to we are converting them to\n",
    "    #integers so that they will work on our Neural Network\n",
    "    for parameter_name in ['nb_neurons', 'nb_layers']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    #Create and compile our network, from the parameters that the TPE choses. \n",
    "    model = create_and_compile(params)\n",
    "    #Generate the accuracy of the parameters\n",
    "    cv_results = cross_validate(model,X_train, y_train)\n",
    "    #This allows us to keep track of how long it takes to run the 5 fold CV on our NN.\n",
    "    #This is important if we need to make comprimises on speed VS accuracy.\n",
    "    #The more nodes/layers that you have, the longer it takes for the NN to train/run\n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # We take 1 - our accuracy to get how far away our model is from 100% accuracy. \n",
    "    loss = 1 - cv_results\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([cv_results, params, ITERATION, run_time])\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick the type of optimization algorithm\n",
    "\n",
    "We are using the TPE which is TREE Parzen Estimator. \n",
    "    The Tree-structured Parzen Estimator builds a model by applying Bayes rule. Instead of directly representing p( y | x) instead it used Bayes rule. Which is p (Y|X) = P(X|Y) * P(Y) / P(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe\n",
    "from hyperopt import Trials\n",
    "from hyperopt import fmin\n",
    "from hyperopt import hp\n",
    "\n",
    "# optimization algorithm\n",
    "tpe_algorithm = tpe.suggest\n",
    "\n",
    "# Keep track of results\n",
    "bayes_trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'nb_layers': hp.quniform('nb_layers', 1,5, 1), #Layers from 1-5, incrementing by 1\n",
    "    'nb_neurons': hp.quniform('nb_neurons', 64, 1024, 64), #NB neurons from 64-1024, incrementing by 64\n",
    "    'activation': hp.choice('activation', ['relu', 'elu', 'tanh', 'sigmoid']), #Chose one of the 4 activations functions for the layers\n",
    "    'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd', 'adagrad',\n",
    "                      'adadelta', 'adamax', 'nadam']) #Chose one of the 7 optimizers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'nb_layers': 4.0,\n",
       " 'nb_neurons': 256.0,\n",
       " 'optimizer': 'rmsprop'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we can see what a random sample from our space looks like\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "sample(space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to save first results\n",
    "out_file = './neural_network.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['accuracy', 'params', 'iteration', 'train_time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Global variable\n",
    "global  ITERATION\n",
    "ITERATION = 0\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = 50, trials = bayes_trials, rstate = np.random.RandomState(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('neural_network.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>params</th>\n",
       "      <th>iteration</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.996401</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>50</td>\n",
       "      <td>102.410144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy                                             params  iteration  \\\n",
       "49  0.996401  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         50   \n",
       "\n",
       "    train_time  \n",
       "49  102.410144  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['accuracy']==max(data['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>params</th>\n",
       "      <th>iteration</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.996401</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>50</td>\n",
       "      <td>102.410144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.996085</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>32</td>\n",
       "      <td>51.653945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.995868</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>33</td>\n",
       "      <td>46.819381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.995785</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 5, 'nb_neu...</td>\n",
       "      <td>38</td>\n",
       "      <td>101.954635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.995768</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>34</td>\n",
       "      <td>42.850932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.995752</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>40</td>\n",
       "      <td>46.352520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.995752</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 2, 'nb_neu...</td>\n",
       "      <td>30</td>\n",
       "      <td>30.873281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.995601</td>\n",
       "      <td>{'activation': 'tanh', 'nb_layers': 1, 'nb_neu...</td>\n",
       "      <td>24</td>\n",
       "      <td>32.251612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.995568</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 2, 'nb_neu...</td>\n",
       "      <td>29</td>\n",
       "      <td>30.348787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.995452</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>46</td>\n",
       "      <td>35.124397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.995285</td>\n",
       "      <td>{'activation': 'tanh', 'nb_layers': 2, 'nb_neu...</td>\n",
       "      <td>27</td>\n",
       "      <td>36.425053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.995002</td>\n",
       "      <td>{'activation': 'tanh', 'nb_layers': 1, 'nb_neu...</td>\n",
       "      <td>21</td>\n",
       "      <td>27.833711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.994968</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>37</td>\n",
       "      <td>53.413505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994935</td>\n",
       "      <td>{'activation': 'tanh', 'nb_layers': 1, 'nb_neu...</td>\n",
       "      <td>4</td>\n",
       "      <td>33.080053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.994885</td>\n",
       "      <td>{'activation': 'tanh', 'nb_layers': 2, 'nb_neu...</td>\n",
       "      <td>25</td>\n",
       "      <td>31.879223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.994852</td>\n",
       "      <td>{'activation': 'tanh', 'nb_layers': 1, 'nb_neu...</td>\n",
       "      <td>23</td>\n",
       "      <td>28.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.994485</td>\n",
       "      <td>{'activation': 'elu', 'nb_layers': 3, 'nb_neur...</td>\n",
       "      <td>5</td>\n",
       "      <td>32.157363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.994435</td>\n",
       "      <td>{'activation': 'tanh', 'nb_layers': 1, 'nb_neu...</td>\n",
       "      <td>26</td>\n",
       "      <td>29.794440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.994351</td>\n",
       "      <td>{'activation': 'tanh', 'nb_layers': 2, 'nb_neu...</td>\n",
       "      <td>28</td>\n",
       "      <td>37.466598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.994118</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 2, 'nb_neu...</td>\n",
       "      <td>49</td>\n",
       "      <td>34.671377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.993835</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 4, 'nb_neu...</td>\n",
       "      <td>47</td>\n",
       "      <td>70.563954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.993768</td>\n",
       "      <td>{'activation': 'tanh', 'nb_layers': 1, 'nb_neu...</td>\n",
       "      <td>22</td>\n",
       "      <td>26.454079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.993685</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 2, 'nb_neu...</td>\n",
       "      <td>7</td>\n",
       "      <td>34.084126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.993385</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>41</td>\n",
       "      <td>31.579072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.993235</td>\n",
       "      <td>{'activation': 'sigmoid', 'nb_layers': 4, 'nb_...</td>\n",
       "      <td>17</td>\n",
       "      <td>64.764417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.993185</td>\n",
       "      <td>{'activation': 'sigmoid', 'nb_layers': 3, 'nb_...</td>\n",
       "      <td>2</td>\n",
       "      <td>34.392365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.993185</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>36</td>\n",
       "      <td>46.258242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.993001</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>44</td>\n",
       "      <td>47.635253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.992785</td>\n",
       "      <td>{'activation': 'sigmoid', 'nb_layers': 5, 'nb_...</td>\n",
       "      <td>18</td>\n",
       "      <td>79.805148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.992718</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 1, 'nb_neu...</td>\n",
       "      <td>31</td>\n",
       "      <td>24.317542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.992652</td>\n",
       "      <td>{'activation': 'sigmoid', 'nb_layers': 1, 'nb_...</td>\n",
       "      <td>14</td>\n",
       "      <td>34.511656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.992635</td>\n",
       "      <td>{'activation': 'sigmoid', 'nb_layers': 4, 'nb_...</td>\n",
       "      <td>9</td>\n",
       "      <td>53.895081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.991852</td>\n",
       "      <td>{'activation': 'sigmoid', 'nb_layers': 4, 'nb_...</td>\n",
       "      <td>19</td>\n",
       "      <td>49.600341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.991785</td>\n",
       "      <td>{'activation': 'elu', 'nb_layers': 3, 'nb_neur...</td>\n",
       "      <td>13</td>\n",
       "      <td>48.212212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.991768</td>\n",
       "      <td>{'activation': 'elu', 'nb_layers': 1, 'nb_neur...</td>\n",
       "      <td>10</td>\n",
       "      <td>26.350034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.991751</td>\n",
       "      <td>{'activation': 'sigmoid', 'nb_layers': 4, 'nb_...</td>\n",
       "      <td>15</td>\n",
       "      <td>122.105618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.991418</td>\n",
       "      <td>{'activation': 'elu', 'nb_layers': 4, 'nb_neur...</td>\n",
       "      <td>42</td>\n",
       "      <td>71.733322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.991335</td>\n",
       "      <td>{'activation': 'tanh', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>3</td>\n",
       "      <td>52.330004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.991201</td>\n",
       "      <td>{'activation': 'sigmoid', 'nb_layers': 2, 'nb_...</td>\n",
       "      <td>8</td>\n",
       "      <td>59.867054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.989835</td>\n",
       "      <td>{'activation': 'sigmoid', 'nb_layers': 5, 'nb_...</td>\n",
       "      <td>16</td>\n",
       "      <td>145.160746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.988452</td>\n",
       "      <td>{'activation': 'elu', 'nb_layers': 2, 'nb_neur...</td>\n",
       "      <td>20</td>\n",
       "      <td>44.125753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.987236</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 4, 'nb_neu...</td>\n",
       "      <td>12</td>\n",
       "      <td>140.833324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.985019</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>35</td>\n",
       "      <td>152.415152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.983985</td>\n",
       "      <td>{'activation': 'sigmoid', 'nb_layers': 2, 'nb_...</td>\n",
       "      <td>11</td>\n",
       "      <td>79.615322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.979785</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 4, 'nb_neu...</td>\n",
       "      <td>39</td>\n",
       "      <td>87.685541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.971552</td>\n",
       "      <td>{'activation': 'elu', 'nb_layers': 4, 'nb_neur...</td>\n",
       "      <td>6</td>\n",
       "      <td>161.483949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.968269</td>\n",
       "      <td>{'activation': 'elu', 'nb_layers': 4, 'nb_neur...</td>\n",
       "      <td>45</td>\n",
       "      <td>100.117032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958653</td>\n",
       "      <td>{'activation': 'tanh', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>1</td>\n",
       "      <td>89.877308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.112367</td>\n",
       "      <td>{'activation': 'elu', 'nb_layers': 5, 'nb_neur...</td>\n",
       "      <td>48</td>\n",
       "      <td>39.730227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.102183</td>\n",
       "      <td>{'activation': 'relu', 'nb_layers': 3, 'nb_neu...</td>\n",
       "      <td>43</td>\n",
       "      <td>51.025012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy                                             params  iteration  \\\n",
       "49  0.996401  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         50   \n",
       "31  0.996085  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         32   \n",
       "32  0.995868  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         33   \n",
       "37  0.995785  {'activation': 'relu', 'nb_layers': 5, 'nb_neu...         38   \n",
       "33  0.995768  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         34   \n",
       "39  0.995752  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         40   \n",
       "29  0.995752  {'activation': 'relu', 'nb_layers': 2, 'nb_neu...         30   \n",
       "23  0.995601  {'activation': 'tanh', 'nb_layers': 1, 'nb_neu...         24   \n",
       "28  0.995568  {'activation': 'relu', 'nb_layers': 2, 'nb_neu...         29   \n",
       "45  0.995452  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         46   \n",
       "26  0.995285  {'activation': 'tanh', 'nb_layers': 2, 'nb_neu...         27   \n",
       "20  0.995002  {'activation': 'tanh', 'nb_layers': 1, 'nb_neu...         21   \n",
       "36  0.994968  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         37   \n",
       "3   0.994935  {'activation': 'tanh', 'nb_layers': 1, 'nb_neu...          4   \n",
       "24  0.994885  {'activation': 'tanh', 'nb_layers': 2, 'nb_neu...         25   \n",
       "22  0.994852  {'activation': 'tanh', 'nb_layers': 1, 'nb_neu...         23   \n",
       "4   0.994485  {'activation': 'elu', 'nb_layers': 3, 'nb_neur...          5   \n",
       "25  0.994435  {'activation': 'tanh', 'nb_layers': 1, 'nb_neu...         26   \n",
       "27  0.994351  {'activation': 'tanh', 'nb_layers': 2, 'nb_neu...         28   \n",
       "48  0.994118  {'activation': 'relu', 'nb_layers': 2, 'nb_neu...         49   \n",
       "46  0.993835  {'activation': 'relu', 'nb_layers': 4, 'nb_neu...         47   \n",
       "21  0.993768  {'activation': 'tanh', 'nb_layers': 1, 'nb_neu...         22   \n",
       "6   0.993685  {'activation': 'relu', 'nb_layers': 2, 'nb_neu...          7   \n",
       "40  0.993385  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         41   \n",
       "16  0.993235  {'activation': 'sigmoid', 'nb_layers': 4, 'nb_...         17   \n",
       "1   0.993185  {'activation': 'sigmoid', 'nb_layers': 3, 'nb_...          2   \n",
       "35  0.993185  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         36   \n",
       "43  0.993001  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         44   \n",
       "17  0.992785  {'activation': 'sigmoid', 'nb_layers': 5, 'nb_...         18   \n",
       "30  0.992718  {'activation': 'relu', 'nb_layers': 1, 'nb_neu...         31   \n",
       "13  0.992652  {'activation': 'sigmoid', 'nb_layers': 1, 'nb_...         14   \n",
       "8   0.992635  {'activation': 'sigmoid', 'nb_layers': 4, 'nb_...          9   \n",
       "18  0.991852  {'activation': 'sigmoid', 'nb_layers': 4, 'nb_...         19   \n",
       "12  0.991785  {'activation': 'elu', 'nb_layers': 3, 'nb_neur...         13   \n",
       "9   0.991768  {'activation': 'elu', 'nb_layers': 1, 'nb_neur...         10   \n",
       "14  0.991751  {'activation': 'sigmoid', 'nb_layers': 4, 'nb_...         15   \n",
       "41  0.991418  {'activation': 'elu', 'nb_layers': 4, 'nb_neur...         42   \n",
       "2   0.991335  {'activation': 'tanh', 'nb_layers': 3, 'nb_neu...          3   \n",
       "7   0.991201  {'activation': 'sigmoid', 'nb_layers': 2, 'nb_...          8   \n",
       "15  0.989835  {'activation': 'sigmoid', 'nb_layers': 5, 'nb_...         16   \n",
       "19  0.988452  {'activation': 'elu', 'nb_layers': 2, 'nb_neur...         20   \n",
       "11  0.987236  {'activation': 'relu', 'nb_layers': 4, 'nb_neu...         12   \n",
       "34  0.985019  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         35   \n",
       "10  0.983985  {'activation': 'sigmoid', 'nb_layers': 2, 'nb_...         11   \n",
       "38  0.979785  {'activation': 'relu', 'nb_layers': 4, 'nb_neu...         39   \n",
       "5   0.971552  {'activation': 'elu', 'nb_layers': 4, 'nb_neur...          6   \n",
       "44  0.968269  {'activation': 'elu', 'nb_layers': 4, 'nb_neur...         45   \n",
       "0   0.958653  {'activation': 'tanh', 'nb_layers': 3, 'nb_neu...          1   \n",
       "47  0.112367  {'activation': 'elu', 'nb_layers': 5, 'nb_neur...         48   \n",
       "42  0.102183  {'activation': 'relu', 'nb_layers': 3, 'nb_neu...         43   \n",
       "\n",
       "    train_time  \n",
       "49  102.410144  \n",
       "31   51.653945  \n",
       "32   46.819381  \n",
       "37  101.954635  \n",
       "33   42.850932  \n",
       "39   46.352520  \n",
       "29   30.873281  \n",
       "23   32.251612  \n",
       "28   30.348787  \n",
       "45   35.124397  \n",
       "26   36.425053  \n",
       "20   27.833711  \n",
       "36   53.413505  \n",
       "3    33.080053  \n",
       "24   31.879223  \n",
       "22   28.000020  \n",
       "4    32.157363  \n",
       "25   29.794440  \n",
       "27   37.466598  \n",
       "48   34.671377  \n",
       "46   70.563954  \n",
       "21   26.454079  \n",
       "6    34.084126  \n",
       "40   31.579072  \n",
       "16   64.764417  \n",
       "1    34.392365  \n",
       "35   46.258242  \n",
       "43   47.635253  \n",
       "17   79.805148  \n",
       "30   24.317542  \n",
       "13   34.511656  \n",
       "8    53.895081  \n",
       "18   49.600341  \n",
       "12   48.212212  \n",
       "9    26.350034  \n",
       "14  122.105618  \n",
       "41   71.733322  \n",
       "2    52.330004  \n",
       "7    59.867054  \n",
       "15  145.160746  \n",
       "19   44.125753  \n",
       "11  140.833324  \n",
       "34  152.415152  \n",
       "10   79.615322  \n",
       "38   87.685541  \n",
       "5   161.483949  \n",
       "44  100.117032  \n",
       "0    89.877308  \n",
       "47   39.730227  \n",
       "42   51.025012  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values('accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
