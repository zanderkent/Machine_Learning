{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read through the whole tutorial before attemping to run it yourself\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Bayesian Optimization.\n",
    "### Bayesian optimization is a sequential design strategy for global optimization of black-box functions that doesn't require derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "MAX_EVALS = 500\n",
    "N_FOLDS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to take parameters and return a compiled NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping after 10 epochs of little decrease in our loss function.\n",
    "early_stopper = EarlyStopping(patience=10)\n",
    "def create_and_compile(network):\n",
    "    \"\"\"Network is a dictionary\"\"\"\n",
    "    input_shape = (784,)\n",
    "    nb_layers = network['nb_layers']\n",
    "    nb_neurons = network['nb_neurons']\n",
    "    activation = network['activation']\n",
    "    optimizer = network['optimizer']\n",
    "    #learning_rate = network['learning_rate'] TODO figure out how to add learning rate to an activation function\n",
    "    #Define the type of model\n",
    "    #A Sequential model, is a series of fully connected (DENSE) layers that are connected in sequence.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nb_neurons, activation=activation, input_shape=input_shape, name='input_layer'))\n",
    "    model.add(Dropout(rate=0.2, name='dropout_input'))\n",
    "    for i in range(nb_layers):\n",
    "        model.add(Dense(nb_neurons, activation=activation, name='layer_{}'.format(i+1)))\n",
    "        #Dropout to help avoid over-fitting\n",
    "        model.add(Dropout(rate=0.2, name='dropout_{}'.format(i+1)))\n",
    "    # Output layer.\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our Cross validation function\n",
    "This is the function that we want to use to optimize towards. Typically you \"one hot encode\" your target to be a vector of records, N_classes. But since the Kfolds cross validation needs to take a single volumn vector, we will one hot encode the values AFTER we split our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model,X=None,y=None,num_fold=5):\n",
    "    kFold = StratifiedKFold(n_splits=5)\n",
    "    generator = kFold.split(X, y)\n",
    "    Y_train = np_utils.to_categorical(y, 10)\n",
    "    scores = []\n",
    "    for val in generator:\n",
    "        model.fit(x=X[val[0]], y=Y_train[val[0]], batch_size=512,\n",
    "                  validation_data = [X[val[1]],Y_train[val[1]]],\n",
    "                  epochs=100, verbose=0, callbacks = [early_stopper])\n",
    "        scores.append(model.evaluate(X[val[1]],Y_train[val[1]]))\n",
    "    return np.array(scores)[:,1].mean() # 1 is accuracy, 0 is loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the y label to see the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(y_train[:], edgecolor = 'k'); \n",
    "plt.xlabel('Label'); plt.ylabel('Count'); plt.title('Counts of Labels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and normalize input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n",
      "Train matrix shape (60000, 784)\n",
      "Test matrix shape (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# let's print the shape before we reshape and normalize\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n",
    "\n",
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# print the final input shape ready for training\n",
    "print(\"Train matrix shape\", X_train.shape)\n",
    "print(\"Test matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine baseline model\n",
    "Created a simple NN to get a baseline to show our improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12005/12005 [==============================] - 1s 102us/step\n",
      "12002/12002 [==============================] - 1s 95us/step\n",
      "12000/12000 [==============================] - 1s 96us/step\n",
      "11997/11997 [==============================] - 1s 94us/step\n",
      "11996/11996 [==============================] - 1s 94us/step\n",
      "The baseline score on the test set is 0.9935.\n",
      "The baseline training time is 70.1870 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "network = {'nb_layers':1, 'nb_neurons':784, 'activation':'relu','optimizer':'adam'}\n",
    "model = create_and_compile(network)\n",
    "results = cross_validate(model, X_train, y_train)\n",
    "train_time = timer() - start\n",
    "\n",
    "print('The baseline score on the test set is {:.4f}.'.format(results))\n",
    "print('The baseline training time is {:.4f} seconds'.format(train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the objective function for which we are going to optimize\n",
    "Essentially we are going to create, train and validate our model and check to see how close it is to 100%. \n",
    "Since we are trying to maximize our accuracy. We are taking the 1 - accuracy to get the difference. \n",
    "For example, if our model is 99% accurate, we are 1% away from 100%. We will minimze our \"loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "def objective(params, n_folds = 5):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    sys.stdout.flush()\n",
    "    start = timer()\n",
    "    #When using Hyperpot to generate our lists, it creates them as floats, to we are converting them to\n",
    "    #integers so that they will work on our Neural Network\n",
    "    for parameter_name in ['nb_neurons', 'nb_layers']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    #Create and compile our network, from the parameters that the TPE choses. \n",
    "    model = create_and_compile(params)\n",
    "    #Generate the accuracy of the parameters\n",
    "    cv_results = cross_validate(model,X_train, y_train)\n",
    "    #This allows us to keep track of how long it takes to run the 5 fold CV on our NN.\n",
    "    #This is important if we need to make comprimises on speed VS accuracy.\n",
    "    #The more nodes/layers that you have, the longer it takes for the NN to train/run\n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # We take 1 - our accuracy to get how far away our model is from 100% accuracy. \n",
    "    loss = 1 - cv_results\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([cv_results, params, ITERATION, run_time])\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick the type of optimization algorithm\n",
    "\n",
    "We are using the TPE which is TREE Parzen Estimator. \n",
    "    The Tree-structured Parzen Estimator builds a model by applying Bayes rule. Instead of directly representing p( y | x) instead it used Bayes rule. Which is \n",
    "$$\n",
    "\\begin{equation} \n",
    "p(Y|X) = \\frac{(X|Y)*P(Y)}{P(X)}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe, Trials, fmin, hp\n",
    "\n",
    "# optimization algorithm\n",
    "tpe_algorithm = tpe.suggest\n",
    "\n",
    "# Keep track of results\n",
    "bayes_trials = Trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to use hyperopt.hp to use in our optimization\n",
    "This allows the optimzation to pick the combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'nb_layers': hp.quniform('nb_layers', 1,5, 1), #Layers from 1-5, incrementing by 1\n",
    "    'nb_neurons': hp.quniform('nb_neurons', 64, 1024, 64), #NB neurons from 64-1024, incrementing by 64\n",
    "    'activation': hp.choice('activation', ['relu', 'elu', 'tanh', 'sigmoid']), #Chose one of the 4 activations functions for the layers\n",
    "    'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd', 'adagrad',\n",
    "                      'adadelta', 'adamax', 'nadam']) #Chose one of the 7 optimizers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'sigmoid',\n",
       " 'nb_layers': 3.0,\n",
       " 'nb_neurons': 192.0,\n",
       " 'optimizer': 'adamax'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we can see what a random sample from our space looks like\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "sample(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we are creating an output file to write the records to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to save first results\n",
    "out_file = './neural_network.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['accuracy', 'params', 'iteration', 'train_time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is where all the magic happens\n",
    "We are passing the objective, the space, the optimization algo, maximum evals and the trial tracking\n",
    "###### Objective: This is the custom objective function that we created \n",
    "###### space: is the search space, all of the hyper-parameters we are using to tune\n",
    "###### algo: the tpe algo we are using, see above\n",
    "###### max_evals: number of iterations you want to go through before you stop\n",
    "###### trials: this keeps track of all of the different options the algo has tried\n",
    "###### rstate: random state that needs to be used (check documentation for more information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can review the trials in the network.csv as the trials run through.\n",
    "\n",
    "%%capture\n",
    "\n",
    "# Global variable\n",
    "global  ITERATION\n",
    "ITERATION = 0\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe_algorithm, \n",
    "            max_evals = 50, trials = bayes_trials, rstate = np.random.RandomState(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
